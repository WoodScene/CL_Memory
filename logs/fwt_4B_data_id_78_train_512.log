nohup: ignoring input
======== å¼€å§‹è®­ç»ƒ dataset_id=7, task_id=0 ========

Training Qwen3 FWT LoRA model with params:
base_model: /workspace/Qwen3-4B
batch_size: 32
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 512
val_set_size: 20
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
add_eos_token: True
group_by_length: True
wandb_project: fwt
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca
dataset_id: 7
task_id: 0


current service name: task1572... begin fine tuning!
output_dir: /workspace/CL_exp/checkpoints/exp_3_4B_512/Qwen3-4Blora_fwt_dataset_id_7/0-task1572
current data path: ./data/train/task1572.json
æ€»æ ·æœ¬æ•°ï¼š160
lora_weights: 

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.11it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.12it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.66it/s]
Qwen tokenizer config: bos=None, eos=151645, pad=151643
FWT: fine tune Qwen LoRA from scratch for this task!
trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733
Map:   0%|          | 0/20 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 498.30 examples/s]
Map:   0%|          | 0/160 [00:00<?, ? examples/s]Map:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 93/160 [00:00<00:00, 917.32 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:00<00:00, 876.08 examples/s]
âš™ï¸  Running in WANDB offline mode
The model is already on multiple devices. Skipping the move to device specified in `args`.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145142-3hg962vq
  0%|          | 0/50 [00:00<?, ?it/s]  2%|â–         | 1/50 [00:03<02:26,  3.00s/it]  4%|â–         | 2/50 [00:04<01:52,  2.34s/it]  6%|â–Œ         | 3/50 [00:06<01:39,  2.11s/it]  8%|â–Š         | 4/50 [00:08<01:35,  2.08s/it] 10%|â–ˆ         | 5/50 [00:10<01:30,  2.01s/it] 12%|â–ˆâ–        | 6/50 [00:12<01:28,  2.01s/it] 14%|â–ˆâ–        | 7/50 [00:14<01:24,  1.95s/it] 16%|â–ˆâ–Œ        | 8/50 [00:16<01:23,  1.99s/it] 18%|â–ˆâ–Š        | 9/50 [00:18<01:19,  1.93s/it] 20%|â–ˆâ–ˆ        | 10/50 [00:20<01:15,  1.88s/it]                                               {'loss': 3.5394, 'grad_norm': 3.5547072887420654, 'learning_rate': 5.399999999999999e-05, 'epoch': 2.0}
 20%|â–ˆâ–ˆ        | 10/50 [00:20<01:15,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 11/50 [00:21<01:11,  1.84s/it] 24%|â–ˆâ–ˆâ–       | 12/50 [00:23<01:09,  1.82s/it] 26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:25<01:07,  1.84s/it] 28%|â–ˆâ–ˆâ–Š       | 14/50 [00:27<01:07,  1.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:29<01:06,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:31<01:04,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:33<01:03,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:35<01:02,  1.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:37<00:59,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:39<00:56,  1.89s/it]                                               {'loss': 2.8262, 'grad_norm': 1.5260783433914185, 'learning_rate': 0.00011399999999999999, 'epoch': 4.0}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:39<00:56,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:41<00:55,  1.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:42<00:53,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:44<00:50,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:46<00:49,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:48<00:46,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:50<00:44,  1.84s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:52<00:43,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:54<00:41,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:55<00:39,  1.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:57<00:37,  1.89s/it]                                               {'loss': 2.0878, 'grad_norm': 1.0272313356399536, 'learning_rate': 0.00017399999999999997, 'epoch': 6.0}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:57<00:37,  1.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:59<00:36,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [01:01<00:34,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [01:03<00:31,  1.85s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [01:05<00:29,  1.83s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [01:07<00:28,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [01:09<00:26,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [01:11<00:24,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [01:12<00:22,  1.85s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [01:14<00:20,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:16<00:18,  1.88s/it]                                               {'loss': 1.4373, 'grad_norm': 0.9058222770690918, 'learning_rate': 0.000234, 'epoch': 8.0}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:16<00:18,  1.88s/it]
  0%|          | 0/3 [00:00<?, ?it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  6.22it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.75it/s][A                                               
                                             [A{'eval_loss': 1.2999544143676758, 'eval_runtime': 0.7952, 'eval_samples_per_second': 25.15, 'eval_steps_per_second': 3.772, 'epoch': 8.0}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:17<00:18,  1.88s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.75it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [01:19<00:19,  2.20s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [01:21<00:16,  2.07s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [01:23<00:14,  2.03s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [01:25<00:11,  1.99s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [01:27<00:09,  1.95s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [01:29<00:07,  1.95s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [01:30<00:05,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [01:32<00:03,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [01:34<00:01,  1.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:36<00:00,  1.88s/it]                                               {'loss': 1.0485, 'grad_norm': 0.816190242767334, 'learning_rate': 0.000294, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:36<00:00,  1.88s/it]/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
                                               {'train_runtime': 97.3584, 'train_samples_per_second': 16.434, 'train_steps_per_second': 0.514, 'train_loss': 2.1878361892700195, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:36<00:00,  1.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:36<00:00,  1.93s/it]

 If there's a warning about missing keys above, please disregard :)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145142-3hg962vq[0m
[1;34mwandb[0m: Find logs at: [1;35m../CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145142-3hg962vq/logs[0m
[rank0]:[W1123 14:53:20.665099786 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
======== å¼€å§‹è®­ç»ƒ dataset_id=7, task_id=1 ========

Training Qwen3 FWT LoRA model with params:
base_model: /workspace/Qwen3-4B
batch_size: 32
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 512
val_set_size: 20
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
add_eos_token: True
group_by_length: True
wandb_project: fwt
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca
dataset_id: 7
task_id: 1


current service name: task363... begin fine tuning!
output_dir: /workspace/CL_exp/checkpoints/exp_3_4B_512/Qwen3-4Blora_fwt_dataset_id_7/1-task363
current data path: ./data/train/task363.json
æ€»æ ·æœ¬æ•°ï¼š1000
lora_weights: 

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.28it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.29it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.91it/s]
Qwen tokenizer config: bos=None, eos=151645, pad=151643
FWT: fine tune Qwen LoRA from scratch for this task!
trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733
Map:   0%|          | 0/45 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:00<00:00, 790.39 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map:  18%|â–ˆâ–Š        | 177/1000 [00:00<00:00, 1759.11 examples/s]Map:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 362/1000 [00:00<00:00, 1805.52 examples/s]Map:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545/1000 [00:00<00:00, 1811.26 examples/s]Map:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 815/1000 [00:00<00:00, 1798.23 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1617.68 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1684.00 examples/s]
âš™ï¸  Running in WANDB offline mode
The model is already on multiple devices. Skipping the move to device specified in `args`.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145335-wyw1h206
  0%|          | 0/320 [00:00<?, ?it/s]  0%|          | 1/320 [00:01<10:21,  1.95s/it]  1%|          | 2/320 [00:03<08:09,  1.54s/it]  1%|          | 3/320 [00:04<06:33,  1.24s/it]  1%|â–         | 4/320 [00:04<05:50,  1.11s/it]  2%|â–         | 5/320 [00:05<05:25,  1.03s/it]  2%|â–         | 6/320 [00:06<05:14,  1.00s/it]  2%|â–         | 7/320 [00:07<05:05,  1.03it/s]  2%|â–Ž         | 8/320 [00:08<05:04,  1.02it/s]  3%|â–Ž         | 9/320 [00:09<04:57,  1.04it/s]  3%|â–Ž         | 10/320 [00:10<04:51,  1.06it/s]                                                {'loss': 12.5273, 'grad_norm': 10.735832214355469, 'learning_rate': 5.399999999999999e-05, 'epoch': 0.32}
  3%|â–Ž         | 10/320 [00:10<04:51,  1.06it/s]  3%|â–Ž         | 11/320 [00:11<04:45,  1.08it/s]  4%|â–         | 12/320 [00:12<04:43,  1.09it/s]  4%|â–         | 13/320 [00:13<04:39,  1.10it/s]  4%|â–         | 14/320 [00:14<04:38,  1.10it/s]  5%|â–         | 15/320 [00:15<04:44,  1.07it/s]  5%|â–Œ         | 16/320 [00:16<04:41,  1.08it/s]  5%|â–Œ         | 17/320 [00:16<04:38,  1.09it/s]  6%|â–Œ         | 18/320 [00:17<04:34,  1.10it/s]  6%|â–Œ         | 19/320 [00:18<04:32,  1.10it/s]  6%|â–‹         | 20/320 [00:19<04:31,  1.11it/s]                                                {'loss': 9.8276, 'grad_norm': 11.349571228027344, 'learning_rate': 0.00011399999999999999, 'epoch': 0.64}
  6%|â–‹         | 20/320 [00:19<04:31,  1.11it/s]  7%|â–‹         | 21/320 [00:20<04:32,  1.10it/s]  7%|â–‹         | 22/320 [00:21<04:39,  1.07it/s]  7%|â–‹         | 23/320 [00:22<04:37,  1.07it/s]  8%|â–Š         | 24/320 [00:23<04:33,  1.08it/s]  8%|â–Š         | 25/320 [00:24<04:28,  1.10it/s]  8%|â–Š         | 26/320 [00:25<04:27,  1.10it/s]  8%|â–Š         | 27/320 [00:26<04:24,  1.11it/s]  9%|â–‰         | 28/320 [00:26<04:23,  1.11it/s]  9%|â–‰         | 29/320 [00:27<04:27,  1.09it/s]  9%|â–‰         | 30/320 [00:28<04:24,  1.10it/s]                                                {'loss': 3.631, 'grad_norm': 7.63201904296875, 'learning_rate': 0.00017399999999999997, 'epoch': 0.96}
  9%|â–‰         | 30/320 [00:28<04:24,  1.10it/s] 10%|â–‰         | 31/320 [00:29<04:23,  1.10it/s] 10%|â–ˆ         | 32/320 [00:29<03:23,  1.41it/s] 10%|â–ˆ         | 33/320 [00:30<03:48,  1.26it/s] 11%|â–ˆ         | 34/320 [00:31<04:00,  1.19it/s] 11%|â–ˆ         | 35/320 [00:32<04:04,  1.16it/s] 11%|â–ˆâ–        | 36/320 [00:33<04:06,  1.15it/s] 12%|â–ˆâ–        | 37/320 [00:34<04:08,  1.14it/s] 12%|â–ˆâ–        | 38/320 [00:35<04:07,  1.14it/s] 12%|â–ˆâ–        | 39/320 [00:36<04:09,  1.13it/s] 12%|â–ˆâ–Ž        | 40/320 [00:37<04:15,  1.10it/s]                                                {'loss': 0.1863, 'grad_norm': 10.112299919128418, 'learning_rate': 0.000234, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [00:37<04:15,  1.10it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  6.97it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.76it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  5.16it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  4.79it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.71it/s][A                                                
                                             [A{'eval_loss': 2.391188621520996, 'eval_runtime': 1.5063, 'eval_samples_per_second': 29.874, 'eval_steps_per_second': 3.983, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [00:38<04:15,  1.10it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.71it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 13%|â–ˆâ–Ž        | 41/320 [00:39<06:39,  1.43s/it] 13%|â–ˆâ–Ž        | 42/320 [00:40<05:55,  1.28s/it] 13%|â–ˆâ–Ž        | 43/320 [00:41<05:21,  1.16s/it] 14%|â–ˆâ–        | 44/320 [00:42<04:58,  1.08s/it] 14%|â–ˆâ–        | 45/320 [00:43<04:43,  1.03s/it] 14%|â–ˆâ–        | 46/320 [00:44<04:31,  1.01it/s] 15%|â–ˆâ–        | 47/320 [00:45<04:29,  1.01it/s] 15%|â–ˆâ–Œ        | 48/320 [00:46<04:23,  1.03it/s] 15%|â–ˆâ–Œ        | 49/320 [00:47<04:17,  1.05it/s] 16%|â–ˆâ–Œ        | 50/320 [00:48<04:11,  1.08it/s]                                                {'loss': 0.193, 'grad_norm': 0.8641640543937683, 'learning_rate': 0.000294, 'epoch': 1.58}
 16%|â–ˆâ–Œ        | 50/320 [00:48<04:11,  1.08it/s] 16%|â–ˆâ–Œ        | 51/320 [00:49<04:08,  1.08it/s] 16%|â–ˆâ–‹        | 52/320 [00:50<04:08,  1.08it/s] 17%|â–ˆâ–‹        | 53/320 [00:50<04:07,  1.08it/s] 17%|â–ˆâ–‹        | 54/320 [00:51<04:11,  1.06it/s] 17%|â–ˆâ–‹        | 55/320 [00:52<04:08,  1.06it/s] 18%|â–ˆâ–Š        | 56/320 [00:53<04:05,  1.08it/s] 18%|â–ˆâ–Š        | 57/320 [00:54<04:02,  1.09it/s] 18%|â–ˆâ–Š        | 58/320 [00:55<03:59,  1.09it/s] 18%|â–ˆâ–Š        | 59/320 [00:56<03:56,  1.10it/s] 19%|â–ˆâ–‰        | 60/320 [00:57<03:55,  1.10it/s]                                                {'loss': 0.2241, 'grad_norm': 0.9552671313285828, 'learning_rate': 0.00029, 'epoch': 1.9}
 19%|â–ˆâ–‰        | 60/320 [00:57<03:55,  1.10it/s] 19%|â–ˆâ–‰        | 61/320 [00:58<03:59,  1.08it/s] 19%|â–ˆâ–‰        | 62/320 [00:59<03:58,  1.08it/s] 20%|â–ˆâ–‰        | 63/320 [01:00<03:56,  1.08it/s] 20%|â–ˆâ–ˆ        | 64/320 [01:00<03:03,  1.40it/s] 20%|â–ˆâ–ˆ        | 65/320 [01:01<03:23,  1.25it/s] 21%|â–ˆâ–ˆ        | 66/320 [01:02<03:31,  1.20it/s] 21%|â–ˆâ–ˆ        | 67/320 [01:03<03:36,  1.17it/s] 21%|â–ˆâ–ˆâ–       | 68/320 [01:04<03:39,  1.15it/s] 22%|â–ˆâ–ˆâ–       | 69/320 [01:05<03:39,  1.14it/s] 22%|â–ˆâ–ˆâ–       | 70/320 [01:05<03:38,  1.14it/s]                                                {'loss': 0.1228, 'grad_norm': 0.8170180320739746, 'learning_rate': 0.00027888888888888885, 'epoch': 2.19}
 22%|â–ˆâ–ˆâ–       | 70/320 [01:05<03:38,  1.14it/s] 22%|â–ˆâ–ˆâ–       | 71/320 [01:06<03:40,  1.13it/s] 22%|â–ˆâ–ˆâ–Ž       | 72/320 [01:07<03:45,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 73/320 [01:08<03:45,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 74/320 [01:09<03:43,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 75/320 [01:10<03:40,  1.11it/s] 24%|â–ˆâ–ˆâ–       | 76/320 [01:11<03:39,  1.11it/s] 24%|â–ˆâ–ˆâ–       | 77/320 [01:12<03:37,  1.12it/s] 24%|â–ˆâ–ˆâ–       | 78/320 [01:13<03:37,  1.11it/s] 25%|â–ˆâ–ˆâ–       | 79/320 [01:14<03:42,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 80/320 [01:15<03:41,  1.08it/s]                                                {'loss': 0.1366, 'grad_norm': 0.4796324074268341, 'learning_rate': 0.00026777777777777775, 'epoch': 2.51}
 25%|â–ˆâ–ˆâ–Œ       | 80/320 [01:15<03:41,  1.08it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.06it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.66it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  4.75it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:01<00:00,  4.65it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.36it/s][A                                                
                                             [A{'eval_loss': 2.225539445877075, 'eval_runtime': 1.3919, 'eval_samples_per_second': 32.33, 'eval_steps_per_second': 4.311, 'epoch': 2.51}
 25%|â–ˆâ–ˆâ–Œ       | 80/320 [01:16<03:41,  1.08it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.36it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 25%|â–ˆâ–ˆâ–Œ       | 81/320 [01:17<05:33,  1.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 82/320 [01:18<04:56,  1.25s/it] 26%|â–ˆâ–ˆâ–Œ       | 83/320 [01:19<04:30,  1.14s/it] 26%|â–ˆâ–ˆâ–‹       | 84/320 [01:20<04:11,  1.07s/it] 27%|â–ˆâ–ˆâ–‹       | 85/320 [01:21<04:00,  1.02s/it] 27%|â–ˆâ–ˆâ–‹       | 86/320 [01:22<03:56,  1.01s/it] 27%|â–ˆâ–ˆâ–‹       | 87/320 [01:23<03:50,  1.01it/s] 28%|â–ˆâ–ˆâ–Š       | 88/320 [01:24<03:42,  1.04it/s] 28%|â–ˆâ–ˆâ–Š       | 89/320 [01:24<03:36,  1.07it/s] 28%|â–ˆâ–ˆâ–Š       | 90/320 [01:25<03:33,  1.08it/s]                                                {'loss': 0.1172, 'grad_norm': 0.6282870769500732, 'learning_rate': 0.00025666666666666665, 'epoch': 2.83}
 28%|â–ˆâ–ˆâ–Š       | 90/320 [01:25<03:33,  1.08it/s] 28%|â–ˆâ–ˆâ–Š       | 91/320 [01:26<03:29,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 92/320 [01:27<03:28,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 93/320 [01:28<03:28,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 94/320 [01:29<03:24,  1.10it/s] 30%|â–ˆâ–ˆâ–‰       | 95/320 [01:30<03:22,  1.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 96/320 [01:30<02:36,  1.43it/s] 30%|â–ˆâ–ˆâ–ˆ       | 97/320 [01:31<02:54,  1.28it/s] 31%|â–ˆâ–ˆâ–ˆ       | 98/320 [01:32<03:02,  1.21it/s] 31%|â–ˆâ–ˆâ–ˆ       | 99/320 [01:33<03:06,  1.18it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 100/320 [01:34<03:07,  1.17it/s]                                                 {'loss': 0.1115, 'grad_norm': 0.4509011507034302, 'learning_rate': 0.00024555555555555556, 'epoch': 3.13}
 31%|â–ˆâ–ˆâ–ˆâ–      | 100/320 [01:34<03:07,  1.17it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 101/320 [01:35<03:09,  1.16it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 102/320 [01:35<03:10,  1.15it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 103/320 [01:36<03:11,  1.13it/s] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 104/320 [01:37<03:17,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 105/320 [01:38<03:18,  1.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 106/320 [01:39<03:15,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 107/320 [01:40<03:13,  1.10it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 108/320 [01:41<03:11,  1.11it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 109/320 [01:42<03:09,  1.12it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 110/320 [01:43<03:09,  1.11it/s]                                                 {'loss': 0.0965, 'grad_norm': 0.7128573656082153, 'learning_rate': 0.0002344444444444444, 'epoch': 3.45}
 34%|â–ˆâ–ˆâ–ˆâ–      | 110/320 [01:43<03:09,  1.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 111/320 [01:44<03:12,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 112/320 [01:45<03:11,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 113/320 [01:46<03:08,  1.10it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 114/320 [01:46<03:05,  1.11it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 115/320 [01:47<03:04,  1.11it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 116/320 [01:48<03:01,  1.12it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 117/320 [01:49<03:01,  1.12it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 118/320 [01:50<03:04,  1.09it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 119/320 [01:51<03:04,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [01:52<03:02,  1.10it/s]                                                 {'loss': 0.0728, 'grad_norm': 0.712313175201416, 'learning_rate': 0.00022333333333333333, 'epoch': 3.77}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [01:52<03:02,  1.10it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  9.05it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  6.82it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  6.03it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  5.16it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.32it/s][A                                                 
                                             [A{'eval_loss': 2.1702728271484375, 'eval_runtime': 1.3008, 'eval_samples_per_second': 34.595, 'eval_steps_per_second': 4.613, 'epoch': 3.77}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [01:53<03:02,  1.10it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.32it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 121/320 [01:54<04:30,  1.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 122/320 [01:55<04:02,  1.22s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 123/320 [01:56<03:40,  1.12s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 124/320 [01:57<03:26,  1.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 125/320 [01:58<03:19,  1.02s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 126/320 [01:59<03:09,  1.02it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 127/320 [02:00<03:03,  1.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 128/320 [02:00<02:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 129/320 [02:01<02:33,  1.24it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 130/320 [02:02<02:39,  1.19it/s]                                                 {'loss': 0.0588, 'grad_norm': 0.2282990664243698, 'learning_rate': 0.0002122222222222222, 'epoch': 4.06}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 130/320 [02:02<02:39,  1.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 131/320 [02:03<02:41,  1.17it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/320 [02:04<02:42,  1.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/320 [02:04<02:42,  1.15it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/320 [02:05<02:42,  1.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 135/320 [02:06<02:43,  1.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 136/320 [02:07<02:48,  1.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 137/320 [02:08<02:46,  1.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 138/320 [02:09<02:44,  1.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 139/320 [02:10<02:41,  1.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/320 [02:11<02:40,  1.12it/s]                                                 {'loss': 0.0514, 'grad_norm': 0.7685552835464478, 'learning_rate': 0.0002011111111111111, 'epoch': 4.38}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/320 [02:11<02:40,  1.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/320 [02:12<02:40,  1.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 142/320 [02:13<02:39,  1.11it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/320 [02:14<02:42,  1.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 144/320 [02:14<02:41,  1.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 145/320 [02:15<02:39,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 146/320 [02:16<02:38,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 147/320 [02:17<02:36,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 148/320 [02:18<02:34,  1.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 149/320 [02:19<02:34,  1.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 150/320 [02:20<02:37,  1.08it/s]                                                 {'loss': 0.0541, 'grad_norm': 0.16858772933483124, 'learning_rate': 0.00018999999999999998, 'epoch': 4.7}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 150/320 [02:20<02:37,  1.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 151/320 [02:21<02:38,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 152/320 [02:22<02:38,  1.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 153/320 [02:23<02:34,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 154/320 [02:24<02:32,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 155/320 [02:25<02:29,  1.11it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 156/320 [02:25<02:28,  1.11it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 157/320 [02:26<02:30,  1.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 158/320 [02:27<02:28,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 159/320 [02:28<02:26,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [02:28<01:52,  1.42it/s]                                                 {'loss': 0.0536, 'grad_norm': 0.9902334809303284, 'learning_rate': 0.00017888888888888889, 'epoch': 5.0}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [02:28<01:52,  1.42it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.06it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.46it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  4.97it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:01<00:00,  4.44it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.79it/s][A                                                 
                                             [A{'eval_loss': 2.23610258102417, 'eval_runtime': 1.465, 'eval_samples_per_second': 30.717, 'eval_steps_per_second': 4.096, 'epoch': 5.0}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [02:30<01:52,  1.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.79it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 161/320 [02:31<03:26,  1.30s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 162/320 [02:32<03:06,  1.18s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 163/320 [02:33<02:51,  1.09s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/320 [02:34<02:40,  1.03s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 165/320 [02:35<02:33,  1.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 166/320 [02:36<02:27,  1.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 167/320 [02:36<02:23,  1.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 168/320 [02:37<02:24,  1.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 169/320 [02:38<02:21,  1.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 170/320 [02:39<02:18,  1.08it/s]                                                 {'loss': 0.0071, 'grad_norm': 0.08349351584911346, 'learning_rate': 0.00016777777777777776, 'epoch': 5.32}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 170/320 [02:39<02:18,  1.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 171/320 [02:40<02:16,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/320 [02:41<02:14,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/320 [02:42<02:11,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 174/320 [02:43<02:11,  1.11it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 175/320 [02:44<02:14,  1.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 176/320 [02:45<02:12,  1.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 177/320 [02:46<02:10,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 178/320 [02:46<02:08,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 179/320 [02:47<02:07,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/320 [02:48<02:05,  1.11it/s]                                                 {'loss': 0.0448, 'grad_norm': 0.18683134019374847, 'learning_rate': 0.00015666666666666666, 'epoch': 5.64}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/320 [02:48<02:05,  1.11it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 181/320 [02:49<02:05,  1.11it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 182/320 [02:50<02:07,  1.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 183/320 [02:51<02:06,  1.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 184/320 [02:52<02:04,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 185/320 [02:53<02:02,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 186/320 [02:54<02:00,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 187/320 [02:55<01:59,  1.11it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 188/320 [02:56<01:58,  1.11it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 189/320 [02:56<02:00,  1.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 190/320 [02:57<01:58,  1.10it/s]                                                 {'loss': 0.025, 'grad_norm': 0.7376884818077087, 'learning_rate': 0.00014555555555555554, 'epoch': 5.96}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 190/320 [02:57<01:58,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 191/320 [02:58<01:56,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 192/320 [02:58<01:30,  1.42it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 193/320 [02:59<01:39,  1.28it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 194/320 [03:00<01:43,  1.21it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 195/320 [03:01<01:45,  1.18it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 196/320 [03:02<01:45,  1.17it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 197/320 [03:03<01:46,  1.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 198/320 [03:04<01:45,  1.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 199/320 [03:05<01:46,  1.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [03:06<01:49,  1.10it/s]                                                 {'loss': 0.0127, 'grad_norm': 0.05144587904214859, 'learning_rate': 0.00013444444444444444, 'epoch': 6.26}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [03:06<01:49,  1.10it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.61it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.74it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  4.99it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:01<00:00,  4.45it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.56it/s][A                                                 
                                             [A{'eval_loss': 2.399285316467285, 'eval_runtime': 1.501, 'eval_samples_per_second': 29.98, 'eval_steps_per_second': 3.997, 'epoch': 6.26}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [03:07<01:49,  1.10it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.56it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 201/320 [03:08<02:50,  1.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 202/320 [03:09<02:30,  1.27s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 203/320 [03:10<02:16,  1.16s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 204/320 [03:11<02:05,  1.08s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 205/320 [03:12<01:57,  1.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 206/320 [03:13<01:52,  1.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 207/320 [03:14<01:51,  1.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 208/320 [03:15<01:48,  1.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 209/320 [03:16<01:44,  1.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 210/320 [03:17<01:41,  1.08it/s]                                                 {'loss': 0.0216, 'grad_norm': 0.6319504380226135, 'learning_rate': 0.0001233333333333333, 'epoch': 6.58}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 210/320 [03:17<01:41,  1.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 211/320 [03:18<01:40,  1.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 212/320 [03:18<01:39,  1.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 213/320 [03:19<01:38,  1.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 214/320 [03:20<01:39,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 215/320 [03:21<01:37,  1.07it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 216/320 [03:22<01:36,  1.08it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 217/320 [03:23<01:34,  1.09it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 218/320 [03:24<01:33,  1.09it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 219/320 [03:25<01:32,  1.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/320 [03:26<01:31,  1.09it/s]                                                 {'loss': 0.0116, 'grad_norm': 0.07257338613271713, 'learning_rate': 0.0001122222222222222, 'epoch': 6.9}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/320 [03:26<01:31,  1.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 221/320 [03:27<01:32,  1.07it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 222/320 [03:28<01:30,  1.08it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 223/320 [03:29<01:28,  1.09it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 224/320 [03:29<01:08,  1.41it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 225/320 [03:30<01:15,  1.26it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 226/320 [03:31<01:18,  1.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 227/320 [03:32<01:19,  1.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 228/320 [03:32<01:19,  1.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 229/320 [03:33<01:19,  1.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/320 [03:34<01:18,  1.14it/s]                                                 {'loss': 0.0338, 'grad_norm': 0.4611652195453644, 'learning_rate': 0.0001011111111111111, 'epoch': 7.19}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/320 [03:34<01:18,  1.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 231/320 [03:35<01:18,  1.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 232/320 [03:36<01:19,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 233/320 [03:37<01:19,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 234/320 [03:38<01:18,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 235/320 [03:39<01:16,  1.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 236/320 [03:40<01:15,  1.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 237/320 [03:41<01:14,  1.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 238/320 [03:42<01:13,  1.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 239/320 [03:43<01:14,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [03:43<01:13,  1.09it/s]                                                 {'loss': 0.0057, 'grad_norm': 0.14066103100776672, 'learning_rate': 8.999999999999999e-05, 'epoch': 7.51}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [03:43<01:13,  1.09it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.18it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.15it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  4.52it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:01<00:00,  4.46it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.71it/s][A                                                 
                                             [A{'eval_loss': 2.345893144607544, 'eval_runtime': 1.5254, 'eval_samples_per_second': 29.501, 'eval_steps_per_second': 3.933, 'epoch': 7.51}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [03:45<01:13,  1.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.71it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 241/320 [03:46<01:53,  1.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 242/320 [03:47<01:38,  1.27s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 243/320 [03:48<01:29,  1.16s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 244/320 [03:49<01:22,  1.08s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 245/320 [03:50<01:17,  1.03s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 246/320 [03:51<01:15,  1.02s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 247/320 [03:52<01:11,  1.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 248/320 [03:52<01:08,  1.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 249/320 [03:53<01:06,  1.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 250/320 [03:54<01:04,  1.08it/s]                                                 {'loss': 0.0098, 'grad_norm': 0.02494383230805397, 'learning_rate': 7.888888888888888e-05, 'epoch': 7.83}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 250/320 [03:54<01:04,  1.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 251/320 [03:55<01:02,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 252/320 [03:56<01:01,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 253/320 [03:57<01:01,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 254/320 [03:58<01:00,  1.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 255/320 [03:59<00:59,  1.10it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 256/320 [03:59<00:45,  1.41it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 257/320 [04:00<00:49,  1.26it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 258/320 [04:01<00:51,  1.21it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 259/320 [04:02<00:51,  1.18it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/320 [04:03<00:51,  1.16it/s]                                                 {'loss': 0.0234, 'grad_norm': 1.36356782913208, 'learning_rate': 6.777777777777777e-05, 'epoch': 8.13}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/320 [04:03<00:51,  1.16it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 261/320 [04:04<00:51,  1.15it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 262/320 [04:04<00:50,  1.14it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 263/320 [04:05<00:50,  1.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 264/320 [04:06<00:50,  1.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 265/320 [04:07<00:49,  1.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 266/320 [04:08<00:48,  1.11it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 267/320 [04:09<00:47,  1.11it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 268/320 [04:10<00:46,  1.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 269/320 [04:11<00:45,  1.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 270/320 [04:12<00:44,  1.12it/s]                                                 {'loss': 0.0106, 'grad_norm': 0.07823315262794495, 'learning_rate': 5.666666666666666e-05, 'epoch': 8.45}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 270/320 [04:12<00:44,  1.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 271/320 [04:13<00:45,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 272/320 [04:14<00:44,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 273/320 [04:14<00:43,  1.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 274/320 [04:15<00:41,  1.10it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 275/320 [04:16<00:40,  1.10it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 276/320 [04:17<00:39,  1.11it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 277/320 [04:18<00:38,  1.10it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 278/320 [04:19<00:38,  1.08it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 279/320 [04:20<00:37,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [04:21<00:36,  1.09it/s]                                                 {'loss': 0.0157, 'grad_norm': 0.9454686641693115, 'learning_rate': 4.555555555555555e-05, 'epoch': 8.77}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [04:21<00:36,  1.09it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  7.17it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  5.84it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  5.22it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  5.31it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.39it/s][A                                                 
                                             [A{'eval_loss': 2.45157790184021, 'eval_runtime': 1.3915, 'eval_samples_per_second': 32.34, 'eval_steps_per_second': 4.312, 'epoch': 8.77}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [04:22<00:36,  1.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.39it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 281/320 [04:23<00:54,  1.39s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 282/320 [04:24<00:47,  1.24s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 283/320 [04:25<00:42,  1.14s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 284/320 [04:26<00:38,  1.07s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 285/320 [04:27<00:36,  1.03s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 286/320 [04:28<00:33,  1.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 287/320 [04:29<00:31,  1.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 288/320 [04:29<00:23,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 289/320 [04:30<00:25,  1.22it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 290/320 [04:31<00:25,  1.17it/s]                                                 {'loss': 0.0031, 'grad_norm': 0.2216271013021469, 'learning_rate': 3.444444444444444e-05, 'epoch': 9.06}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 290/320 [04:31<00:25,  1.17it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 291/320 [04:32<00:25,  1.15it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 292/320 [04:33<00:24,  1.14it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 293/320 [04:34<00:23,  1.14it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 294/320 [04:35<00:22,  1.14it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 295/320 [04:35<00:22,  1.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 296/320 [04:36<00:21,  1.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 297/320 [04:37<00:21,  1.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 298/320 [04:38<00:19,  1.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 299/320 [04:39<00:18,  1.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 300/320 [04:40<00:17,  1.11it/s]                                                 {'loss': 0.016, 'grad_norm': 0.029260758310556412, 'learning_rate': 2.3333333333333332e-05, 'epoch': 9.38}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 300/320 [04:40<00:17,  1.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 301/320 [04:41<00:17,  1.12it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 302/320 [04:42<00:16,  1.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 303/320 [04:43<00:15,  1.08it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 304/320 [04:44<00:14,  1.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 305/320 [04:45<00:13,  1.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 306/320 [04:45<00:12,  1.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 307/320 [04:46<00:11,  1.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 308/320 [04:47<00:10,  1.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 309/320 [04:48<00:09,  1.10it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 310/320 [04:49<00:09,  1.08it/s]                                                 {'loss': 0.0076, 'grad_norm': 0.028992703184485435, 'learning_rate': 1.2222222222222222e-05, 'epoch': 9.7}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 310/320 [04:49<00:09,  1.08it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 311/320 [04:50<00:08,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 312/320 [04:51<00:07,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 313/320 [04:52<00:06,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 314/320 [04:53<00:05,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 315/320 [04:54<00:04,  1.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 316/320 [04:55<00:03,  1.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 317/320 [04:55<00:02,  1.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 318/320 [04:56<00:01,  1.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 319/320 [04:57<00:00,  1.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [04:58<00:00,  1.42it/s]                                                 {'loss': 0.0012, 'grad_norm': 0.03713361173868179, 'learning_rate': 1.111111111111111e-06, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [04:58<00:00,  1.42it/s]
  0%|          | 0/6 [00:00<?, ?it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  8.54it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  6.53it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  6.43it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  6.01it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  5.57it/s][A                                                 
                                             [A{'eval_loss': 2.3999221324920654, 'eval_runtime': 1.2979, 'eval_samples_per_second': 34.671, 'eval_steps_per_second': 4.623, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [04:59<00:00,  1.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.57it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
                                                 {'train_runtime': 300.0986, 'train_samples_per_second': 33.322, 'train_steps_per_second': 1.066, 'train_loss': 0.8660669111472089, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [04:59<00:00,  1.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [04:59<00:00,  1.07it/s]

 If there's a warning about missing keys above, please disregard :)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145335-wyw1h206[0m
[1;34mwandb[0m: Find logs at: [1;35m../CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145335-wyw1h206/logs[0m
[rank0]:[W1123 14:58:36.773090900 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
======== å¼€å§‹è®­ç»ƒ dataset_id=7, task_id=2 ========

Training Qwen3 FWT LoRA model with params:
base_model: /workspace/Qwen3-4B
batch_size: 32
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 512
val_set_size: 20
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
add_eos_token: True
group_by_length: True
wandb_project: fwt
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca
dataset_id: 7
task_id: 2


current service name: task1290... begin fine tuning!
output_dir: /workspace/CL_exp/checkpoints/exp_3_4B_512/Qwen3-4Blora_fwt_dataset_id_7/2-task1290
current data path: ./data/train/task1290.json
æ€»æ ·æœ¬æ•°ï¼š1000
lora_weights: 

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.40it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.41it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]
Qwen tokenizer config: bos=None, eos=151645, pad=151643
FWT: fine tune Qwen LoRA from scratch for this task!
trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<00:00, 634.34 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<00:00, 625.48 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map:   4%|â–         | 45/1000 [00:00<00:02, 439.06 examples/s]Map:  11%|â–ˆ         | 109/1000 [00:00<00:02, 426.45 examples/s]Map:  15%|â–ˆâ–Œ        | 154/1000 [00:00<00:01, 432.50 examples/s]Map:  21%|â–ˆâ–ˆâ–       | 213/1000 [00:00<00:01, 412.19 examples/s]Map:  26%|â–ˆâ–ˆâ–Œ       | 260/1000 [00:00<00:01, 422.19 examples/s]Map:  31%|â–ˆâ–ˆâ–ˆ       | 311/1000 [00:00<00:01, 446.92 examples/s]Map:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358/1000 [00:00<00:01, 450.83 examples/s]Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 405/1000 [00:00<00:01, 455.44 examples/s]Map:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465/1000 [00:01<00:01, 430.70 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532/1000 [00:01<00:01, 427.91 examples/s]Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 597/1000 [00:01<00:00, 419.09 examples/s]Map:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 656/1000 [00:01<00:00, 407.47 examples/s]Map:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 705/1000 [00:01<00:00, 425.07 examples/s]Map:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 754/1000 [00:01<00:00, 438.40 examples/s]Map:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814/1000 [00:01<00:00, 421.75 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857/1000 [00:02<00:00, 420.57 examples/s]Map:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [00:02<00:00, 416.44 examples/s]Map:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942/1000 [00:02<00:00, 414.32 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998/1000 [00:02<00:00, 393.96 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 398.46 examples/s]
âš™ï¸  Running in WANDB offline mode
The model is already on multiple devices. Skipping the move to device specified in `args`.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145858-qkqss4jq
  0%|          | 0/320 [00:00<?, ?it/s]  0%|          | 1/320 [00:03<20:13,  3.81s/it]  1%|          | 2/320 [00:06<17:51,  3.37s/it]  1%|          | 3/320 [00:09<17:03,  3.23s/it]  1%|â–         | 4/320 [00:13<17:01,  3.23s/it]  2%|â–         | 5/320 [00:15<16:09,  3.08s/it]  2%|â–         | 6/320 [00:18<14:29,  2.77s/it]  2%|â–         | 7/320 [00:19<12:10,  2.33s/it]  2%|â–Ž         | 8/320 [00:22<13:18,  2.56s/it]  3%|â–Ž         | 9/320 [00:25<14:03,  2.71s/it]  3%|â–Ž         | 10/320 [00:28<14:35,  2.83s/it]                                                {'loss': 3.6693, 'grad_norm': 3.192199230194092, 'learning_rate': 5.399999999999999e-05, 'epoch': 0.32}
  3%|â–Ž         | 10/320 [00:28<14:35,  2.83s/it]  3%|â–Ž         | 11/320 [00:31<14:56,  2.90s/it]  4%|â–         | 12/320 [00:34<14:23,  2.80s/it]  4%|â–         | 13/320 [00:36<13:08,  2.57s/it]  4%|â–         | 14/320 [00:37<11:19,  2.22s/it]  5%|â–         | 15/320 [00:40<12:33,  2.47s/it]  5%|â–Œ         | 16/320 [00:43<13:23,  2.64s/it]  5%|â–Œ         | 17/320 [00:47<14:00,  2.77s/it]  6%|â–Œ         | 18/320 [00:50<14:28,  2.87s/it]  6%|â–Œ         | 19/320 [00:52<13:58,  2.79s/it]  6%|â–‹         | 20/320 [00:54<12:52,  2.58s/it]                                                {'loss': 3.3466, 'grad_norm': 2.482983112335205, 'learning_rate': 0.00011399999999999999, 'epoch': 0.64}
  6%|â–‹         | 20/320 [00:54<12:52,  2.58s/it]  7%|â–‹         | 21/320 [00:56<11:06,  2.23s/it]  7%|â–‹         | 22/320 [00:59<12:17,  2.47s/it]  7%|â–‹         | 23/320 [01:02<13:05,  2.64s/it]  8%|â–Š         | 24/320 [01:05<13:41,  2.77s/it]  8%|â–Š         | 25/320 [01:08<14:04,  2.86s/it]  8%|â–Š         | 26/320 [01:10<13:31,  2.76s/it]  8%|â–Š         | 27/320 [01:13<12:26,  2.55s/it]  9%|â–‰         | 28/320 [01:14<10:44,  2.21s/it]  9%|â–‰         | 29/320 [01:17<11:54,  2.46s/it]  9%|â–‰         | 30/320 [01:20<12:43,  2.63s/it]                                                {'loss': 2.5341, 'grad_norm': 1.826107382774353, 'learning_rate': 0.00017399999999999997, 'epoch': 0.96}
  9%|â–‰         | 30/320 [01:20<12:43,  2.63s/it] 10%|â–‰         | 31/320 [01:22<11:50,  2.46s/it] 10%|â–ˆ         | 32/320 [01:22<08:44,  1.82s/it] 10%|â–ˆ         | 33/320 [01:25<10:28,  2.19s/it] 11%|â–ˆ         | 34/320 [01:28<11:39,  2.45s/it] 11%|â–ˆ         | 35/320 [01:32<12:38,  2.66s/it] 11%|â–ˆâ–        | 36/320 [01:35<13:02,  2.75s/it] 12%|â–ˆâ–        | 37/320 [01:37<12:27,  2.64s/it] 12%|â–ˆâ–        | 38/320 [01:39<11:22,  2.42s/it] 12%|â–ˆâ–        | 39/320 [01:40<09:47,  2.09s/it] 12%|â–ˆâ–Ž        | 40/320 [01:43<11:05,  2.38s/it]                                                {'loss': 2.1164, 'grad_norm': 1.895982265472412, 'learning_rate': 0.000234, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [01:43<11:05,  2.38s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  9.24it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  5.70it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00,  5.34it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00,  4.68it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.67it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.32it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.05it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.03it/s][A                                                
                                             [A{'eval_loss': 1.7160142660140991, 'eval_runtime': 2.3055, 'eval_samples_per_second': 30.362, 'eval_steps_per_second': 3.904, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [01:46<11:05,  2.38s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.03it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 13%|â–ˆâ–Ž        | 41/320 [01:49<15:30,  3.34s/it] 13%|â–ˆâ–Ž        | 42/320 [01:52<15:02,  3.25s/it] 13%|â–ˆâ–Ž        | 43/320 [01:55<14:43,  3.19s/it] 14%|â–ˆâ–        | 44/320 [01:57<13:47,  3.00s/it] 14%|â–ˆâ–        | 45/320 [02:00<12:26,  2.72s/it] 14%|â–ˆâ–        | 46/320 [02:01<10:39,  2.33s/it] 15%|â–ˆâ–        | 47/320 [02:04<11:34,  2.55s/it] 15%|â–ˆâ–Œ        | 48/320 [02:07<12:12,  2.69s/it] 15%|â–ˆâ–Œ        | 49/320 [02:10<12:38,  2.80s/it] 16%|â–ˆâ–Œ        | 50/320 [02:13<13:04,  2.91s/it]                                                {'loss': 1.8263, 'grad_norm': 0.8534952402114868, 'learning_rate': 0.000294, 'epoch': 1.58}
 16%|â–ˆâ–Œ        | 50/320 [02:13<13:04,  2.91s/it] 16%|â–ˆâ–Œ        | 51/320 [02:16<12:44,  2.84s/it] 16%|â–ˆâ–‹        | 52/320 [02:18<11:43,  2.62s/it] 17%|â–ˆâ–‹        | 53/320 [02:20<10:08,  2.28s/it] 17%|â–ˆâ–‹        | 54/320 [02:23<11:07,  2.51s/it] 17%|â–ˆâ–‹        | 55/320 [02:26<11:47,  2.67s/it] 18%|â–ˆâ–Š        | 56/320 [02:29<12:17,  2.79s/it] 18%|â–ˆâ–Š        | 57/320 [02:32<12:41,  2.90s/it] 18%|â–ˆâ–Š        | 58/320 [02:35<12:19,  2.82s/it] 18%|â–ˆâ–Š        | 59/320 [02:37<11:11,  2.57s/it] 19%|â–ˆâ–‰        | 60/320 [02:38<09:34,  2.21s/it]                                                {'loss': 1.7348, 'grad_norm': 0.7953153848648071, 'learning_rate': 0.00029, 'epoch': 1.9}
 19%|â–ˆâ–‰        | 60/320 [02:38<09:34,  2.21s/it] 19%|â–ˆâ–‰        | 61/320 [02:41<10:37,  2.46s/it] 19%|â–ˆâ–‰        | 62/320 [02:44<11:27,  2.67s/it] 20%|â–ˆâ–‰        | 63/320 [02:46<11:00,  2.57s/it] 20%|â–ˆâ–ˆ        | 64/320 [02:47<08:06,  1.90s/it] 20%|â–ˆâ–ˆ        | 65/320 [02:50<09:32,  2.24s/it] 21%|â–ˆâ–ˆ        | 66/320 [02:53<10:31,  2.48s/it] 21%|â–ˆâ–ˆ        | 67/320 [02:56<11:15,  2.67s/it] 21%|â–ˆâ–ˆâ–       | 68/320 [02:59<11:35,  2.76s/it] 22%|â–ˆâ–ˆâ–       | 69/320 [03:01<11:04,  2.65s/it] 22%|â–ˆâ–ˆâ–       | 70/320 [03:03<10:07,  2.43s/it]                                                {'loss': 1.5138, 'grad_norm': 0.6736458539962769, 'learning_rate': 0.00027888888888888885, 'epoch': 2.19}
 22%|â–ˆâ–ˆâ–       | 70/320 [03:03<10:07,  2.43s/it] 22%|â–ˆâ–ˆâ–       | 71/320 [03:05<08:43,  2.10s/it] 22%|â–ˆâ–ˆâ–Ž       | 72/320 [03:08<09:51,  2.38s/it] 23%|â–ˆâ–ˆâ–Ž       | 73/320 [03:11<10:37,  2.58s/it] 23%|â–ˆâ–ˆâ–Ž       | 74/320 [03:14<11:09,  2.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 75/320 [03:17<11:39,  2.86s/it] 24%|â–ˆâ–ˆâ–       | 76/320 [03:20<11:26,  2.81s/it] 24%|â–ˆâ–ˆâ–       | 77/320 [03:22<10:35,  2.62s/it] 24%|â–ˆâ–ˆâ–       | 78/320 [03:23<09:14,  2.29s/it] 25%|â–ˆâ–ˆâ–       | 79/320 [03:26<10:06,  2.52s/it] 25%|â–ˆâ–ˆâ–Œ       | 80/320 [03:29<10:42,  2.68s/it]                                                {'loss': 1.5483, 'grad_norm': 2.4200901985168457, 'learning_rate': 0.00026777777777777775, 'epoch': 2.51}
 25%|â–ˆâ–ˆâ–Œ       | 80/320 [03:29<10:42,  2.68s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00, 10.31it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00,  5.21it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.46it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.25it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  3.93it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.79it/s][A                                                
                                             [A{'eval_loss': 1.5498836040496826, 'eval_runtime': 2.2128, 'eval_samples_per_second': 31.634, 'eval_steps_per_second': 4.067, 'epoch': 2.51}
 25%|â–ˆâ–ˆâ–Œ       | 80/320 [03:32<10:42,  2.68s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.79it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 25%|â–ˆâ–ˆâ–Œ       | 81/320 [03:35<14:04,  3.53s/it] 26%|â–ˆâ–ˆâ–Œ       | 82/320 [03:38<13:27,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 83/320 [03:41<12:27,  3.16s/it] 26%|â–ˆâ–ˆâ–‹       | 84/320 [03:43<11:01,  2.80s/it] 27%|â–ˆâ–ˆâ–‹       | 85/320 [03:44<09:21,  2.39s/it] 27%|â–ˆâ–ˆâ–‹       | 86/320 [03:47<10:04,  2.58s/it] 27%|â–ˆâ–ˆâ–‹       | 87/320 [03:50<10:34,  2.72s/it] 28%|â–ˆâ–ˆâ–Š       | 88/320 [03:53<10:53,  2.82s/it] 28%|â–ˆâ–ˆâ–Š       | 89/320 [03:56<11:11,  2.91s/it] 28%|â–ˆâ–ˆâ–Š       | 90/320 [03:59<10:50,  2.83s/it]                                                {'loss': 1.6184, 'grad_norm': 0.9052395224571228, 'learning_rate': 0.00025666666666666665, 'epoch': 2.83}
 28%|â–ˆâ–ˆâ–Š       | 90/320 [03:59<10:50,  2.83s/it] 28%|â–ˆâ–ˆâ–Š       | 91/320 [04:01<09:56,  2.60s/it] 29%|â–ˆâ–ˆâ–‰       | 92/320 [04:02<08:29,  2.24s/it] 29%|â–ˆâ–ˆâ–‰       | 93/320 [04:05<09:22,  2.48s/it] 29%|â–ˆâ–ˆâ–‰       | 94/320 [04:08<10:01,  2.66s/it] 30%|â–ˆâ–ˆâ–‰       | 95/320 [04:11<09:20,  2.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 96/320 [04:11<06:52,  1.84s/it] 30%|â–ˆâ–ˆâ–ˆ       | 97/320 [04:14<08:11,  2.20s/it] 31%|â–ˆâ–ˆâ–ˆ       | 98/320 [04:17<09:04,  2.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 99/320 [04:20<09:41,  2.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 100/320 [04:23<10:11,  2.78s/it]                                                 {'loss': 1.4333, 'grad_norm': 0.8550926446914673, 'learning_rate': 0.00024555555555555556, 'epoch': 3.13}
 31%|â–ˆâ–ˆâ–ˆâ–      | 100/320 [04:23<10:11,  2.78s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 101/320 [04:26<09:56,  2.73s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 102/320 [04:28<09:06,  2.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 103/320 [04:29<07:49,  2.16s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 104/320 [04:32<08:43,  2.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 105/320 [04:35<09:21,  2.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 106/320 [04:38<09:54,  2.78s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 107/320 [04:41<10:06,  2.85s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 108/320 [04:44<09:41,  2.75s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 109/320 [04:46<08:53,  2.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 110/320 [04:47<07:40,  2.19s/it]                                                 {'loss': 1.3228, 'grad_norm': 1.190150260925293, 'learning_rate': 0.0002344444444444444, 'epoch': 3.45}
 34%|â–ˆâ–ˆâ–ˆâ–      | 110/320 [04:47<07:40,  2.19s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 111/320 [04:50<08:31,  2.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 112/320 [04:53<09:06,  2.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 113/320 [04:56<09:29,  2.75s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 114/320 [05:00<09:51,  2.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 115/320 [05:02<09:47,  2.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 116/320 [05:05<09:05,  2.67s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 117/320 [05:06<07:50,  2.32s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 118/320 [05:09<08:31,  2.53s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 119/320 [05:12<08:59,  2.69s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [05:15<09:20,  2.80s/it]                                                 {'loss': 1.225, 'grad_norm': 3.6625800132751465, 'learning_rate': 0.00022333333333333333, 'epoch': 3.77}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [05:15<09:20,  2.80s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  7.70it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  4.98it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:01,  4.95it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.51it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.14it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  3.81it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.03it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.21it/s][A                                                 
                                             [A{'eval_loss': 1.6326923370361328, 'eval_runtime': 2.3734, 'eval_samples_per_second': 29.494, 'eval_steps_per_second': 3.792, 'epoch': 3.77}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/320 [05:18<09:20,  2.80s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.21it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 121/320 [05:21<12:07,  3.66s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 122/320 [05:23<10:48,  3.28s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 123/320 [05:25<09:30,  2.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 124/320 [05:27<07:56,  2.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 125/320 [05:30<08:29,  2.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 126/320 [05:33<08:53,  2.75s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 127/320 [05:35<08:11,  2.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 128/320 [05:35<06:01,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 129/320 [05:38<07:06,  2.23s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 130/320 [05:41<07:50,  2.48s/it]                                                 {'loss': 1.2875, 'grad_norm': 2.82108473777771, 'learning_rate': 0.0002122222222222222, 'epoch': 4.06}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 130/320 [05:41<07:50,  2.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 131/320 [05:44<08:20,  2.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/320 [05:47<08:43,  2.79s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/320 [05:50<08:23,  2.69s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/320 [05:52<07:44,  2.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 135/320 [05:53<06:40,  2.16s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 136/320 [05:56<07:26,  2.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 137/320 [05:59<07:57,  2.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 138/320 [06:03<08:24,  2.77s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 139/320 [06:06<08:36,  2.85s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/320 [06:08<08:12,  2.74s/it]                                                 {'loss': 1.136, 'grad_norm': 1.8033028841018677, 'learning_rate': 0.0002011111111111111, 'epoch': 4.38}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/320 [06:08<08:12,  2.74s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/320 [06:10<07:30,  2.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 142/320 [06:11<06:26,  2.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/320 [06:14<07:10,  2.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 144/320 [06:18<07:40,  2.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 145/320 [06:21<08:00,  2.74s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 146/320 [06:24<08:16,  2.85s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 147/320 [06:26<08:02,  2.79s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 148/320 [06:28<07:25,  2.59s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 149/320 [06:30<06:24,  2.25s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 150/320 [06:33<07:02,  2.49s/it]                                                 {'loss': 0.9254, 'grad_norm': 2.1451947689056396, 'learning_rate': 0.00018999999999999998, 'epoch': 4.7}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 150/320 [06:33<07:02,  2.49s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 151/320 [06:36<07:28,  2.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 152/320 [06:39<07:45,  2.77s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 153/320 [06:42<07:59,  2.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 154/320 [06:45<07:49,  2.83s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 155/320 [06:47<07:07,  2.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 156/320 [06:48<06:05,  2.23s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 157/320 [06:51<06:43,  2.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 158/320 [06:54<07:13,  2.67s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 159/320 [06:57<06:43,  2.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [06:57<04:56,  1.85s/it]                                                 {'loss': 1.1793, 'grad_norm': 3.57875657081604, 'learning_rate': 0.00017888888888888889, 'epoch': 5.0}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [06:57<04:56,  1.85s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  7.64it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  4.96it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:01,  4.92it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.46it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.50it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.21it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.35it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.63it/s][A                                                 
                                             [A{'eval_loss': 1.9361947774887085, 'eval_runtime': 2.2328, 'eval_samples_per_second': 31.351, 'eval_steps_per_second': 4.031, 'epoch': 5.0}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/320 [06:59<04:56,  1.85s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.63it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 161/320 [07:02<07:48,  2.95s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 162/320 [07:05<07:50,  2.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 163/320 [07:09<07:52,  3.01s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/320 [07:12<07:50,  3.02s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 165/320 [07:14<07:21,  2.85s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 166/320 [07:16<06:42,  2.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 167/320 [07:17<05:42,  2.24s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 168/320 [07:20<06:16,  2.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 169/320 [07:24<06:39,  2.65s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 170/320 [07:27<06:54,  2.77s/it]                                                 {'loss': 0.7308, 'grad_norm': 3.34224271774292, 'learning_rate': 0.00016777777777777776, 'epoch': 5.32}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 170/320 [07:27<06:54,  2.77s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 171/320 [07:30<07:10,  2.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/320 [07:32<06:56,  2.82s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/320 [07:34<06:22,  2.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 174/320 [07:36<05:29,  2.26s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 175/320 [07:39<06:01,  2.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 176/320 [07:42<06:22,  2.66s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 177/320 [07:45<06:36,  2.77s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 178/320 [07:48<06:49,  2.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 179/320 [07:51<06:36,  2.81s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/320 [07:53<06:04,  2.60s/it]                                                 {'loss': 0.8416, 'grad_norm': 3.5862720012664795, 'learning_rate': 0.00015666666666666666, 'epoch': 5.64}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/320 [07:53<06:04,  2.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 181/320 [07:54<05:13,  2.25s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 182/320 [07:57<05:43,  2.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 183/320 [08:00<06:04,  2.66s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 184/320 [08:04<06:18,  2.79s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 185/320 [08:07<06:29,  2.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 186/320 [08:09<06:14,  2.79s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 187/320 [08:11<05:38,  2.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 188/320 [08:13<04:49,  2.19s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 189/320 [08:16<05:20,  2.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 190/320 [08:19<05:40,  2.62s/it]                                                 {'loss': 0.8289, 'grad_norm': 2.6900081634521484, 'learning_rate': 0.00014666666666666664, 'epoch': 5.96}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 190/320 [08:19<05:40,  2.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 191/320 [08:21<05:14,  2.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 192/320 [08:21<03:50,  1.80s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 193/320 [08:24<04:36,  2.17s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 194/320 [08:27<05:06,  2.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 195/320 [08:30<05:28,  2.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 196/320 [08:33<05:43,  2.77s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 197/320 [08:36<05:35,  2.73s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 198/320 [08:38<05:08,  2.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 199/320 [08:39<04:25,  2.19s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [08:42<04:53,  2.45s/it]                                                 {'loss': 0.7549, 'grad_norm': 2.3832743167877197, 'learning_rate': 0.00013555555555555554, 'epoch': 6.26}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [08:42<04:53,  2.45s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  9.61it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  5.86it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:01,  4.89it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.20it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.32it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.10it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.32it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.47it/s][A                                                 
                                             [A{'eval_loss': 2.26497483253479, 'eval_runtime': 2.2647, 'eval_samples_per_second': 30.91, 'eval_steps_per_second': 3.974, 'epoch': 6.26}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 200/320 [08:45<04:53,  2.45s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.47it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 201/320 [08:48<06:41,  3.37s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 202/320 [08:51<06:28,  3.30s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 203/320 [08:54<06:16,  3.22s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 204/320 [08:57<05:48,  3.00s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 205/320 [08:59<05:12,  2.72s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 206/320 [09:00<04:26,  2.33s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 207/320 [09:03<04:47,  2.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 208/320 [09:06<05:01,  2.69s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 209/320 [09:09<05:11,  2.81s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 210/320 [09:12<05:17,  2.89s/it]                                                 {'loss': 0.612, 'grad_norm': 3.219010829925537, 'learning_rate': 0.00012444444444444444, 'epoch': 6.58}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 210/320 [09:12<05:17,  2.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 211/320 [09:15<05:03,  2.78s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 212/320 [09:17<04:35,  2.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 213/320 [09:18<03:57,  2.22s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 214/320 [09:21<04:21,  2.46s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 215/320 [09:24<04:36,  2.64s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 216/320 [09:27<04:46,  2.76s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 217/320 [09:31<04:55,  2.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 218/320 [09:33<04:41,  2.76s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 219/320 [09:35<04:14,  2.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/320 [09:36<03:36,  2.16s/it]                                                 {'loss': 0.7103, 'grad_norm': 2.819521188735962, 'learning_rate': 0.00011333333333333331, 'epoch': 6.9}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/320 [09:36<03:36,  2.16s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 221/320 [09:39<04:00,  2.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 222/320 [09:42<04:16,  2.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 223/320 [09:45<04:07,  2.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 224/320 [09:45<03:00,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 225/320 [09:48<03:31,  2.23s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 226/320 [09:51<03:52,  2.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 227/320 [09:54<04:05,  2.64s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 228/320 [09:57<04:16,  2.79s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 229/320 [10:00<04:08,  2.73s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/320 [10:02<03:46,  2.52s/it]                                                 {'loss': 0.555, 'grad_norm': 2.6306183338165283, 'learning_rate': 0.00010222222222222222, 'epoch': 7.19}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/320 [10:02<03:46,  2.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 231/320 [10:03<03:12,  2.16s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 232/320 [10:06<03:33,  2.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 233/320 [10:09<03:46,  2.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 234/320 [10:12<03:55,  2.74s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 235/320 [10:16<04:03,  2.86s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 236/320 [10:18<03:53,  2.78s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 237/320 [10:20<03:31,  2.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 238/320 [10:22<03:01,  2.21s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 239/320 [10:25<03:19,  2.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [10:28<03:30,  2.64s/it]                                                 {'loss': 0.4443, 'grad_norm': 3.336036443710327, 'learning_rate': 9.11111111111111e-05, 'epoch': 7.51}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [10:28<03:30,  2.64s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  9.19it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  5.69it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00,  5.36it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00,  4.72it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.56it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.18it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.31it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.65it/s][A                                                 
                                             [A{'eval_loss': 2.47357177734375, 'eval_runtime': 2.1748, 'eval_samples_per_second': 32.186, 'eval_steps_per_second': 4.138, 'epoch': 7.51}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/320 [10:30<03:30,  2.64s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.65it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 241/320 [10:33<04:36,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 242/320 [10:36<04:20,  3.34s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 243/320 [10:39<03:58,  3.09s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 244/320 [10:41<03:32,  2.79s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 245/320 [10:42<02:58,  2.39s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 246/320 [10:45<03:11,  2.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 247/320 [10:48<03:18,  2.72s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 248/320 [10:51<03:23,  2.83s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 249/320 [10:55<03:26,  2.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 250/320 [10:57<03:15,  2.80s/it]                                                 {'loss': 0.557, 'grad_norm': 3.0258259773254395, 'learning_rate': 7.999999999999999e-05, 'epoch': 7.83}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 250/320 [10:57<03:15,  2.80s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 251/320 [10:59<02:57,  2.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 252/320 [11:00<02:30,  2.21s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 253/320 [11:04<02:44,  2.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 254/320 [11:07<02:54,  2.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 255/320 [11:09<02:44,  2.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 256/320 [11:09<02:00,  1.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 257/320 [11:12<02:20,  2.23s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 258/320 [11:15<02:33,  2.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 259/320 [11:18<02:41,  2.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/320 [11:21<02:47,  2.79s/it]                                                 {'loss': 0.4749, 'grad_norm': 3.0162580013275146, 'learning_rate': 6.888888888888888e-05, 'epoch': 8.13}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/320 [11:21<02:47,  2.79s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 261/320 [11:24<02:40,  2.71s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 262/320 [11:26<02:25,  2.51s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 263/320 [11:27<02:04,  2.18s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 264/320 [11:31<02:16,  2.44s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 265/320 [11:34<02:23,  2.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 266/320 [11:37<02:29,  2.76s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 267/320 [11:40<02:30,  2.84s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 268/320 [11:42<02:22,  2.74s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 269/320 [11:44<02:08,  2.53s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 270/320 [11:46<01:50,  2.21s/it]                                                 {'loss': 0.5356, 'grad_norm': 2.5789644718170166, 'learning_rate': 5.777777777777777e-05, 'epoch': 8.45}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 270/320 [11:46<01:50,  2.21s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 271/320 [11:49<02:00,  2.46s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 272/320 [11:52<02:06,  2.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 273/320 [11:55<02:10,  2.78s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 274/320 [11:58<02:11,  2.87s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 275/320 [12:01<02:05,  2.79s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 276/320 [12:03<01:52,  2.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 277/320 [12:04<01:34,  2.20s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 278/320 [12:07<01:43,  2.45s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 279/320 [12:10<01:47,  2.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [12:13<01:50,  2.76s/it]                                                 {'loss': 0.3377, 'grad_norm': 2.514876127243042, 'learning_rate': 4.6666666666666665e-05, 'epoch': 8.77}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [12:13<01:50,  2.76s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  9.20it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  5.69it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00,  5.21it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00,  4.57it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.57it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.25it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.30it/s][A                                                 
                                             [A{'eval_loss': 2.6074609756469727, 'eval_runtime': 2.2574, 'eval_samples_per_second': 31.009, 'eval_steps_per_second': 3.987, 'epoch': 8.77}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 280/320 [12:15<01:50,  2.76s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.30it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 281/320 [12:19<02:21,  3.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 282/320 [12:21<02:07,  3.35s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 283/320 [12:24<01:50,  2.99s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 284/320 [12:25<01:31,  2.53s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 285/320 [12:28<01:33,  2.68s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 286/320 [12:31<01:35,  2.80s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 287/320 [12:33<01:24,  2.57s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 288/320 [12:33<01:00,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 289/320 [12:37<01:09,  2.23s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 290/320 [12:40<01:14,  2.48s/it]                                                 {'loss': 0.4938, 'grad_norm': 0.520620584487915, 'learning_rate': 3.555555555555555e-05, 'epoch': 9.06}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 290/320 [12:40<01:14,  2.48s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 291/320 [12:43<01:16,  2.65s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 292/320 [12:46<01:18,  2.80s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 293/320 [12:48<01:13,  2.74s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 294/320 [12:50<01:05,  2.50s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 295/320 [12:52<00:53,  2.15s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 296/320 [12:55<00:58,  2.42s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 297/320 [12:58<00:59,  2.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 298/320 [13:01<01:00,  2.76s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 299/320 [13:04<00:59,  2.84s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 300/320 [13:06<00:54,  2.72s/it]                                                 {'loss': 0.391, 'grad_norm': 3.4090654850006104, 'learning_rate': 2.4444444444444445e-05, 'epoch': 9.38}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 300/320 [13:06<00:54,  2.72s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 301/320 [13:08<00:47,  2.50s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 302/320 [13:10<00:39,  2.17s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 303/320 [13:13<00:41,  2.43s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 304/320 [13:16<00:41,  2.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 305/320 [13:19<00:41,  2.74s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 306/320 [13:22<00:40,  2.86s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 307/320 [13:25<00:36,  2.81s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 308/320 [13:27<00:31,  2.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 309/320 [13:28<00:24,  2.25s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 310/320 [13:31<00:24,  2.49s/it]                                                 {'loss': 0.3792, 'grad_norm': 0.3813014328479767, 'learning_rate': 1.3333333333333333e-05, 'epoch': 9.7}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 310/320 [13:31<00:24,  2.49s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 311/320 [13:34<00:23,  2.65s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 312/320 [13:37<00:22,  2.78s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 313/320 [13:40<00:20,  2.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 314/320 [13:43<00:16,  2.80s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 315/320 [13:45<00:12,  2.58s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 316/320 [13:47<00:08,  2.23s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 317/320 [13:50<00:07,  2.48s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 318/320 [13:53<00:05,  2.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 319/320 [13:55<00:02,  2.50s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [13:55<00:00,  1.85s/it]                                                 {'loss': 0.4168, 'grad_norm': 4.632322788238525, 'learning_rate': 2.222222222222222e-06, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [13:55<00:00,  1.85s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:00<00:00,  9.60it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  5.86it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:00<00:00,  5.31it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:00<00:00,  4.61it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.46it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.11it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:01<00:00,  4.34it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.51it/s][A                                                 
                                             [A{'eval_loss': 2.772413492202759, 'eval_runtime': 2.219, 'eval_samples_per_second': 31.546, 'eval_steps_per_second': 4.056, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [13:57<00:00,  1.85s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.51it/s][A
                                             [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
                                                 {'train_runtime': 838.691, 'train_samples_per_second': 11.923, 'train_steps_per_second': 0.382, 'train_loss': 1.171279889345169, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [13:58<00:00,  1.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [13:58<00:00,  2.62s/it]

 If there's a warning about missing keys above, please disregard :)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145858-qkqss4jq[0m
[1;34mwandb[0m: Find logs at: [1;35m../CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_145858-qkqss4jq/logs[0m
[rank0]:[W1123 15:12:58.414194235 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
======== å¼€å§‹è®­ç»ƒ dataset_id=7, task_id=3 ========

Training Qwen3 FWT LoRA model with params:
base_model: /workspace/Qwen3-4B
batch_size: 32
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 512
val_set_size: 20
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
add_eos_token: True
group_by_length: True
wandb_project: fwt
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca
dataset_id: 7
task_id: 3


current service name: task181... begin fine tuning!
output_dir: /workspace/CL_exp/checkpoints/exp_3_4B_512/Qwen3-4Blora_fwt_dataset_id_7/3-task181
current data path: ./data/train/task181.json
æ€»æ ·æœ¬æ•°ï¼š338
lora_weights: 

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.41it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.42it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]
Qwen tokenizer config: bos=None, eos=151645, pad=151643
FWT: fine tune Qwen LoRA from scratch for this task!
trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733
Map:   0%|          | 0/95 [00:00<?, ? examples/s]Map:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 73/95 [00:00<00:00, 710.49 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:00<00:00, 646.31 examples/s]
Map:   0%|          | 0/338 [00:00<?, ? examples/s]Map:  28%|â–ˆâ–ˆâ–Š       | 96/338 [00:00<00:00, 939.66 examples/s]Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 191/338 [00:00<00:00, 938.17 examples/s]Map:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 330/338 [00:00<00:00, 929.40 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:00<00:00, 857.56 examples/s]
âš™ï¸  Running in WANDB offline mode
The model is already on multiple devices. Skipping the move to device specified in `args`.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_151314-1b2wszo3
  0%|          | 0/110 [00:00<?, ?it/s]  1%|          | 1/110 [00:02<05:02,  2.77s/it]  2%|â–         | 2/110 [00:04<03:44,  2.08s/it]  3%|â–Ž         | 3/110 [00:06<03:28,  1.95s/it]  4%|â–Ž         | 4/110 [00:07<03:11,  1.80s/it]  5%|â–         | 5/110 [00:09<03:11,  1.83s/it]  5%|â–Œ         | 6/110 [00:11<03:00,  1.74s/it]  6%|â–‹         | 7/110 [00:12<03:01,  1.76s/it]  7%|â–‹         | 8/110 [00:14<02:53,  1.70s/it]  8%|â–Š         | 9/110 [00:16<02:53,  1.72s/it]  9%|â–‰         | 10/110 [00:17<02:47,  1.68s/it]                                                {'loss': 7.2214, 'grad_norm': 7.858917236328125, 'learning_rate': 5.399999999999999e-05, 'epoch': 0.94}
  9%|â–‰         | 10/110 [00:17<02:47,  1.68s/it] 10%|â–ˆ         | 11/110 [00:18<02:25,  1.47s/it] 11%|â–ˆ         | 12/110 [00:20<02:34,  1.58s/it] 12%|â–ˆâ–        | 13/110 [00:22<02:33,  1.58s/it] 13%|â–ˆâ–Ž        | 14/110 [00:24<02:36,  1.63s/it] 14%|â–ˆâ–Ž        | 15/110 [00:25<02:33,  1.61s/it] 15%|â–ˆâ–        | 16/110 [00:27<02:37,  1.67s/it] 15%|â–ˆâ–Œ        | 17/110 [00:29<02:32,  1.64s/it] 16%|â–ˆâ–‹        | 18/110 [00:30<02:34,  1.68s/it] 17%|â–ˆâ–‹        | 19/110 [00:32<02:30,  1.65s/it] 18%|â–ˆâ–Š        | 20/110 [00:34<02:31,  1.69s/it]                                                {'loss': 5.2509, 'grad_norm': 3.5324132442474365, 'learning_rate': 0.00011399999999999999, 'epoch': 1.85}
 18%|â–ˆâ–Š        | 20/110 [00:34<02:31,  1.69s/it] 19%|â–ˆâ–‰        | 21/110 [00:35<02:27,  1.65s/it] 20%|â–ˆâ–ˆ        | 22/110 [00:36<02:08,  1.47s/it] 21%|â–ˆâ–ˆ        | 23/110 [00:38<02:16,  1.57s/it] 22%|â–ˆâ–ˆâ–       | 24/110 [00:40<02:14,  1.57s/it] 23%|â–ˆâ–ˆâ–Ž       | 25/110 [00:41<02:18,  1.62s/it] 24%|â–ˆâ–ˆâ–Ž       | 26/110 [00:43<02:15,  1.61s/it] 25%|â–ˆâ–ˆâ–       | 27/110 [00:45<02:17,  1.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 28/110 [00:46<02:13,  1.63s/it] 26%|â–ˆâ–ˆâ–‹       | 29/110 [00:48<02:15,  1.68s/it] 27%|â–ˆâ–ˆâ–‹       | 30/110 [00:50<02:11,  1.65s/it]                                                {'loss': 3.1219, 'grad_norm': 8.069052696228027, 'learning_rate': 0.00017399999999999997, 'epoch': 2.75}
 27%|â–ˆâ–ˆâ–‹       | 30/110 [00:50<02:11,  1.65s/it] 28%|â–ˆâ–ˆâ–Š       | 31/110 [00:51<02:13,  1.69s/it] 29%|â–ˆâ–ˆâ–‰       | 32/110 [00:53<02:09,  1.66s/it] 30%|â–ˆâ–ˆâ–ˆ       | 33/110 [00:54<01:52,  1.46s/it] 31%|â–ˆâ–ˆâ–ˆ       | 34/110 [00:56<01:59,  1.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 35/110 [00:57<01:58,  1.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 36/110 [00:59<02:01,  1.64s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 37/110 [01:01<01:58,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 38/110 [01:03<01:59,  1.66s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 39/110 [01:04<01:56,  1.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 40/110 [01:06<01:57,  1.68s/it]                                                {'loss': 0.7032, 'grad_norm': 2.586089849472046, 'learning_rate': 0.000234, 'epoch': 3.66}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 40/110 [01:06<01:57,  1.68s/it]
  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|â–ˆâ–‹        | 2/12 [00:00<00:01,  8.30it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:00<00:01,  5.47it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:00<00:01,  4.93it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:01<00:01,  4.33it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:01<00:01,  4.28it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:01<00:01,  4.01it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:01<00:00,  4.07it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:02<00:00,  3.89it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:02<00:00,  3.98it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:02<00:00,  3.83it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  3.96it/s][A                                                
                                               [A{'eval_loss': 1.7712849378585815, 'eval_runtime': 3.1167, 'eval_samples_per_second': 30.481, 'eval_steps_per_second': 3.85, 'epoch': 3.66}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 40/110 [01:09<01:57,  1.68s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  3.96it/s][A
                                               [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 41/110 [01:11<03:02,  2.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 42/110 [01:13<02:42,  2.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 43/110 [01:14<02:23,  2.14s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 44/110 [01:15<01:59,  1.80s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 45/110 [01:17<01:57,  1.81s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/110 [01:19<01:51,  1.74s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 47/110 [01:20<01:50,  1.75s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 48/110 [01:22<01:45,  1.70s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 49/110 [01:24<01:44,  1.72s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 50/110 [01:25<01:40,  1.68s/it]                                                {'loss': 0.3422, 'grad_norm': 1.6853984594345093, 'learning_rate': 0.000294, 'epoch': 4.56}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 50/110 [01:25<01:40,  1.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 51/110 [01:27<01:39,  1.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 52/110 [01:29<01:35,  1.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 53/110 [01:30<01:36,  1.70s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 54/110 [01:32<01:32,  1.66s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 55/110 [01:33<01:21,  1.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 56/110 [01:35<01:25,  1.59s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 57/110 [01:36<01:23,  1.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 58/110 [01:38<01:24,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 59/110 [01:40<01:22,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/110 [01:42<01:24,  1.69s/it]                                                {'loss': 0.2205, 'grad_norm': 1.0174931287765503, 'learning_rate': 0.00025499999999999996, 'epoch': 5.47}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/110 [01:42<01:24,  1.69s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 61/110 [01:43<01:20,  1.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 62/110 [01:45<01:22,  1.71s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 63/110 [01:47<01:18,  1.67s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 64/110 [01:48<01:16,  1.67s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 65/110 [01:50<01:13,  1.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 66/110 [01:51<01:03,  1.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 67/110 [01:53<01:07,  1.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 68/110 [01:54<01:05,  1.57s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 69/110 [01:56<01:06,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 70/110 [01:58<01:04,  1.61s/it]                                                {'loss': 0.1508, 'grad_norm': 1.2694916725158691, 'learning_rate': 0.000205, 'epoch': 6.38}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 70/110 [01:58<01:04,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/110 [01:59<01:04,  1.65s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 72/110 [02:01<01:01,  1.63s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 73/110 [02:03<01:02,  1.68s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 74/110 [02:04<00:59,  1.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 75/110 [02:06<00:58,  1.68s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 76/110 [02:08<00:56,  1.65s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 77/110 [02:09<00:48,  1.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 78/110 [02:10<00:49,  1.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 79/110 [02:12<00:48,  1.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 80/110 [02:14<00:48,  1.63s/it]                                                {'loss': 0.0897, 'grad_norm': 1.39167320728302, 'learning_rate': 0.000155, 'epoch': 7.28}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 80/110 [02:14<00:48,  1.63s/it]
  0%|          | 0/12 [00:00<?, ?it/s][A
 17%|â–ˆâ–‹        | 2/12 [00:00<00:01,  8.96it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:00<00:01,  5.64it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:00<00:01,  5.27it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:00<00:01,  4.64it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:01<00:01,  4.48it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:01<00:01,  4.12it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:01<00:00,  4.09it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:02<00:00,  3.87it/s][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:02<00:00,  3.96it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:02<00:00,  3.82it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  3.98it/s][A                                                
                                               [A{'eval_loss': 1.9635794162750244, 'eval_runtime': 3.066, 'eval_samples_per_second': 30.985, 'eval_steps_per_second': 3.914, 'epoch': 7.28}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 80/110 [02:17<00:48,  1.63s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  3.98it/s][A
                                               [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 81/110 [02:19<01:15,  2.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/110 [02:20<01:05,  2.34s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 83/110 [02:22<00:56,  2.11s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 84/110 [02:24<00:52,  2.01s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 85/110 [02:25<00:46,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 86/110 [02:27<00:44,  1.85s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 87/110 [02:29<00:40,  1.77s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 88/110 [02:30<00:34,  1.55s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 89/110 [02:31<00:34,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 90/110 [02:33<00:32,  1.61s/it]                                                {'loss': 0.038, 'grad_norm': 0.6932272911071777, 'learning_rate': 0.00010499999999999999, 'epoch': 8.19}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 90/110 [02:33<00:32,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 91/110 [02:35<00:31,  1.67s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 92/110 [02:36<00:29,  1.64s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/110 [02:38<00:28,  1.68s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 94/110 [02:40<00:26,  1.65s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 95/110 [02:42<00:25,  1.69s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 96/110 [02:43<00:23,  1.66s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 97/110 [02:45<00:22,  1.70s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 98/110 [02:47<00:19,  1.66s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 99/110 [02:47<00:15,  1.45s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 100/110 [02:49<00:15,  1.55s/it]                                                 {'loss': 0.0232, 'grad_norm': 0.548360288143158, 'learning_rate': 5.499999999999999e-05, 'epoch': 9.09}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 100/110 [02:49<00:15,  1.55s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 101/110 [02:51<00:13,  1.55s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 102/110 [02:53<00:13,  1.65s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 103/110 [02:54<00:11,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/110 [02:56<00:10,  1.68s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 105/110 [02:58<00:08,  1.65s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 106/110 [02:59<00:06,  1.67s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 107/110 [03:01<00:04,  1.64s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 108/110 [03:03<00:03,  1.69s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 109/110 [03:04<00:01,  1.66s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [03:05<00:00,  1.45s/it]                                                 {'loss': 0.0116, 'grad_norm': 0.22505876421928406, 'learning_rate': 4.9999999999999996e-06, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [03:05<00:00,  1.45s/it]/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
                                                 {'train_runtime': 186.5351, 'train_samples_per_second': 18.12, 'train_steps_per_second': 0.59, 'train_loss': 1.5612126739187675, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [03:05<00:00,  1.45s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [03:05<00:00,  1.69s/it]

 If there's a warning about missing keys above, please disregard :)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_151314-1b2wszo3[0m
[1;34mwandb[0m: Find logs at: [1;35m../CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_151314-1b2wszo3/logs[0m
[rank0]:[W1123 15:16:21.711637580 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
======== å¼€å§‹è®­ç»ƒ dataset_id=7, task_id=4 ========

Training Qwen3 FWT LoRA model with params:
base_model: /workspace/Qwen3-4B
batch_size: 32
micro_batch_size: 4
num_epochs: 10
learning_rate: 0.0003
max_input_length: 512
val_set_size: 20
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
add_eos_token: True
group_by_length: True
wandb_project: fwt
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca
dataset_id: 7
task_id: 4


current service name: task002... begin fine tuning!
output_dir: /workspace/CL_exp/checkpoints/exp_3_4B_512/Qwen3-4Blora_fwt_dataset_id_7/4-task002
current data path: ./data/train/task002.json
æ€»æ ·æœ¬æ•°ï¼š1000
lora_weights: 

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.11it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.12it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.66it/s]
Qwen tokenizer config: bos=None, eos=151645, pad=151643
FWT: fine tune Qwen LoRA from scratch for this task!
trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733
Map:   0%|          | 0/120 [00:00<?, ? examples/s]Map:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 58/120 [00:00<00:00, 555.63 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 543.15 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 540.41 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map:   4%|â–         | 39/1000 [00:00<00:02, 377.31 examples/s]Map:   8%|â–Š         | 80/1000 [00:00<00:02, 388.61 examples/s]Map:  12%|â–ˆâ–        | 119/1000 [00:00<00:02, 384.30 examples/s]Map:  16%|â–ˆâ–Œ        | 160/1000 [00:00<00:02, 383.04 examples/s]Map:  20%|â–ˆâ–‰        | 199/1000 [00:00<00:02, 383.79 examples/s]Map:  24%|â–ˆâ–ˆâ–       | 241/1000 [00:00<00:01, 392.09 examples/s]Map:  28%|â–ˆâ–ˆâ–Š       | 285/1000 [00:00<00:01, 396.98 examples/s]Map:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 325/1000 [00:00<00:01, 393.80 examples/s]Map:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 385/1000 [00:00<00:01, 393.00 examples/s]Map:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 425/1000 [00:01<00:01, 393.51 examples/s]Map:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465/1000 [00:01<00:01, 390.71 examples/s]Map:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522/1000 [00:01<00:01, 384.13 examples/s]Map:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 561/1000 [00:01<00:01, 382.03 examples/s]Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601/1000 [00:01<00:01, 384.55 examples/s]Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642/1000 [00:01<00:00, 387.32 examples/s]Map:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 682/1000 [00:01<00:00, 389.70 examples/s]Map:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724/1000 [00:01<00:00, 396.15 examples/s]Map:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 766/1000 [00:01<00:00, 399.01 examples/s]Map:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814/1000 [00:02<00:00, 419.04 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 856/1000 [00:02<00:00, 416.14 examples/s]Map:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898/1000 [00:02<00:00, 409.42 examples/s]Map:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942/1000 [00:02<00:00, 361.82 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 999/1000 [00:02<00:00, 364.67 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02<00:00, 364.04 examples/s]
âš™ï¸  Running in WANDB offline mode
The model is already on multiple devices. Skipping the move to device specified in `args`.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /workspace/CL_exp/wandblog/FWT_4B_exp_data_id_78_512/wandb/offline-run-20251123_151640-s02sdbkc
  0%|          | 0/320 [00:00<?, ?it/s]  0%|          | 1/320 [00:03<20:40,  3.89s/it]  1%|          | 2/320 [00:06<17:59,  3.40s/it]  1%|          | 3/320 [00:09<17:06,  3.24s/it]  1%|â–         | 4/320 [00:13<16:40,  3.17s/it]  2%|â–         | 5/320 [00:16<16:57,  3.23s/it]  2%|â–         | 6/320 [00:19<16:42,  3.19s/it]  2%|â–         | 7/320 [00:22<15:57,  3.06s/it]  2%|â–Ž         | 8/320 [00:25<15:53,  3.06s/it]  3%|â–Ž         | 9/320 [00:28<15:50,  3.06s/it]  3%|â–Ž         | 10/320 [00:31<15:46,  3.05s/it]                                                {'loss': 3.9939, 'grad_norm': 5.069818019866943, 'learning_rate': 5.399999999999999e-05, 'epoch': 0.32}
  3%|â–Ž         | 10/320 [00:31<15:46,  3.05s/it]  3%|â–Ž         | 11/320 [00:34<15:47,  3.07s/it]  4%|â–         | 12/320 [00:37<15:59,  3.11s/it]  4%|â–         | 13/320 [00:40<15:50,  3.09s/it]  4%|â–         | 14/320 [00:43<14:58,  2.94s/it]  5%|â–         | 15/320 [00:46<15:05,  2.97s/it]  5%|â–Œ         | 16/320 [00:49<15:10,  2.99s/it]  5%|â–Œ         | 17/320 [00:52<15:12,  3.01s/it]  6%|â–Œ         | 18/320 [00:55<15:12,  3.02s/it]  6%|â–Œ         | 19/320 [00:58<15:35,  3.11s/it]  6%|â–‹         | 20/320 [01:02<15:36,  3.12s/it]                                                {'loss': 4.0435, 'grad_norm': 9.489229202270508, 'learning_rate': 0.00011399999999999999, 'epoch': 0.64}
  6%|â–‹         | 20/320 [01:02<15:36,  3.12s/it]  7%|â–‹         | 21/320 [01:04<14:59,  3.01s/it]  7%|â–‹         | 22/320 [01:07<15:00,  3.02s/it]  7%|â–‹         | 23/320 [01:10<15:00,  3.03s/it]  8%|â–Š         | 24/320 [01:13<14:59,  3.04s/it]  8%|â–Š         | 25/320 [01:17<14:57,  3.04s/it]  8%|â–Š         | 26/320 [01:20<15:13,  3.11s/it]  8%|â–Š         | 27/320 [01:23<15:10,  3.11s/it]  9%|â–‰         | 28/320 [01:25<14:22,  2.95s/it]  9%|â–‰         | 29/320 [01:29<14:27,  2.98s/it]  9%|â–‰         | 30/320 [01:32<14:30,  3.00s/it]                                                {'loss': 2.4936, 'grad_norm': 2.355910062789917, 'learning_rate': 0.00017399999999999997, 'epoch': 0.96}
  9%|â–‰         | 30/320 [01:32<14:30,  3.00s/it] 10%|â–‰         | 31/320 [01:35<14:38,  3.04s/it] 10%|â–ˆ         | 32/320 [01:35<11:08,  2.32s/it] 10%|â–ˆ         | 33/320 [01:38<12:09,  2.54s/it] 11%|â–ˆ         | 34/320 [01:41<12:50,  2.69s/it] 11%|â–ˆ         | 35/320 [01:44<13:17,  2.80s/it] 11%|â–ˆâ–        | 36/320 [01:48<13:39,  2.89s/it] 12%|â–ˆâ–        | 37/320 [01:51<14:08,  3.00s/it] 12%|â–ˆâ–        | 38/320 [01:54<14:10,  3.02s/it] 12%|â–ˆâ–        | 39/320 [01:56<13:32,  2.89s/it] 12%|â–ˆâ–Ž        | 40/320 [02:00<13:43,  2.94s/it]                                                {'loss': 1.5701, 'grad_norm': 3.081531524658203, 'learning_rate': 0.000234, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [02:00<13:43,  2.94s/it]
  0%|          | 0/15 [00:00<?, ?it/s][A
 13%|â–ˆâ–Ž        | 2/15 [00:00<00:01,  7.06it/s][A
 20%|â–ˆâ–ˆ        | 3/15 [00:00<00:01,  6.51it/s][A
 27%|â–ˆâ–ˆâ–‹       | 4/15 [00:00<00:02,  5.05it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:01<00:02,  4.38it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:01<00:01,  4.56it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7/15 [00:01<00:01,  4.29it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8/15 [00:01<00:01,  3.73it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9/15 [00:02<00:01,  3.91it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:02<00:01,  3.88it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:02<00:01,  3.79it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12/15 [00:02<00:00,  4.24it/s][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13/15 [00:03<00:00,  4.05it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:03<00:00,  3.76it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.02it/s][A                                                
                                               [A{'eval_loss': 2.140153169631958, 'eval_runtime': 3.8497, 'eval_samples_per_second': 31.171, 'eval_steps_per_second': 3.896, 'epoch': 1.26}
 12%|â–ˆâ–Ž        | 40/320 [02:03<13:43,  2.94s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.02it/s][A
                                               [A/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
 13%|â–ˆâ–Ž        | 41/320 [02:07<19:32,  4.20s/it]E1123 15:18:49.941000 530906 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: -9) local_rank: 0 (pid: 530971) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
finetune_fwt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-23_15:18:49
  host      : b27963d456a9
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 530971)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 530971
=======================================================
